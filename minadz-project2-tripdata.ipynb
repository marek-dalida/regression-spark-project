{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earned-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('minadz').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attempted-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('yellow_tripdata_2021-01.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formal-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floating-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.summary of DataFrame[VendorID: int, tpep_pickup_datetime: string, tpep_dropoff_datetime: string, passenger_count: int, trip_distance: double, RatecodeID: int, store_and_fwd_flag: string, PULocationID: int, DOLocationID: int, payment_type: int, fare_amount: double, extra: double, mta_tax: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clinical-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"VendorID\", \"PULocationID\", \"RatecodeID\", \"DOLocationID\" )\n",
    "# could also check with dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monetary-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# values Y and N\n",
    "stringIndexer = StringIndexer(inputCol=\"store_and_fwd_flag\", outputCol=\"store_and_fwd_flag_idx\",\n",
    "                              stringOrderType=\"alphabetAsc\", handleInvalid=\"keep\")\n",
    "model = stringIndexer.fit(data)\n",
    "data = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-virtue",
   "metadata": {},
   "source": [
    "### find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brilliant-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>store_and_fwd_flag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98352</td>\n",
       "      <td>0</td>\n",
       "      <td>98352</td>\n",
       "      <td>98352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tpep_pickup_datetime  tpep_dropoff_datetime  passenger_count  \\\n",
       "0                     0                      0            98352   \n",
       "\n",
       "   trip_distance  store_and_fwd_flag  payment_type  fare_amount  extra  \\\n",
       "0              0               98352         98352            0      0   \n",
       "\n",
       "   mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        0           0             0                      0             0   \n",
       "\n",
       "   congestion_surcharge  store_and_fwd_flag_idx  \n",
       "0                     0                       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "\n",
    "nacounts = data.select([count(when(isnull(c), c)).alias(c) for c in data.columns]).toPandas()\n",
    "nacounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developed-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(strategy='median', inputCols=['passenger_count'], outputCols=['passenger_count_imp'])\n",
    "imputer_model = imputer.fit(data)\n",
    "data = imputer_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "auburn-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='mode', inputCols=['store_and_fwd_flag_idx', ], outputCols=['store_and_fwd_flag_imp'])\n",
    "imputer_model = imputer.fit(data)\n",
    "data = imputer_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cooperative-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='mode', inputCols=['payment_type', ], outputCols=['payment_type_imp'])\n",
    "imputer_model = imputer.fit(data)\n",
    "data = imputer_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "right-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['passenger_count_imp', 'trip_distance', 'store_and_fwd_flag_idx', 'payment_type_imp', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge'], outputCol = 'features')\n",
    "vtripdata_df = vectorAssembler.transform(data)\n",
    "vtripdata_df = vtripdata_df.select(['features', 'total_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complete-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|total_amount|\n",
      "+--------------------+------------+\n",
      "|[1.0,2.1,0.0,2.0,...|        11.8|\n",
      "|[1.0,0.2,0.0,2.0,...|         4.3|\n",
      "|[1.0,14.7,0.0,1.0...|       51.95|\n",
      "|[0.0,10.6,0.0,1.0...|       36.35|\n",
      "|[1.0,4.94,0.0,1.0...|       24.36|\n",
      "|[1.0,1.6,0.0,1.0,...|       14.15|\n",
      "|[1.0,4.1,0.0,2.0,...|        17.3|\n",
      "|[1.0,5.7,0.0,2.0,...|        21.8|\n",
      "|[1.0,9.1,0.0,4.0,...|        28.8|\n",
      "|[2.0,2.7,0.0,1.0,...|       18.95|\n",
      "|[3.0,6.11,0.0,1.0...|        24.3|\n",
      "|[2.0,1.21,0.0,1.0...|       10.79|\n",
      "|[2.0,7.4,0.0,2.0,...|       33.92|\n",
      "|[5.0,1.7,0.0,1.0,...|       14.16|\n",
      "|[5.0,0.81,0.0,2.0...|         8.3|\n",
      "|[1.0,1.01,0.0,1.0...|        10.3|\n",
      "|[1.0,0.73,0.0,1.0...|       12.09|\n",
      "|[1.0,1.17,0.0,1.0...|       12.36|\n",
      "|[1.0,0.78,0.0,1.0...|        9.96|\n",
      "|[2.0,1.66,0.0,2.0...|        12.3|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vtripdata_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "verbal-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = vtripdata_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technological-prior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.9827316381065105,0.05754258109856909,0.0,0.9590415329081708,0.9001620556163971,1.7305578221402393,0.5588629007926905]\n",
      "Intercept: 1.7710034249551878\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='total_amount', maxIter=20, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ongoing-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------------+\n",
      "|            features|total_amount|        prediction|\n",
      "+--------------------+------------+------------------+\n",
      "|(11,[0,1,2,3,4,9]...|        62.8| 63.71089815325417|\n",
      "|(11,[0,1,2,3,4,9]...|       100.3|100.56333458224832|\n",
      "|(11,[0,1,2,3,9],[...|         0.3|2.2901707715972597|\n",
      "|(11,[0,1,3],[1.0,...|         0.0|1.7710034249551878|\n",
      "|(11,[0,1,3],[1.0,...|         0.0|1.7710034249551878|\n",
      "+--------------------+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incorporate-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.712911\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cultural-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol = 'features', labelCol='total_amount')\n",
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "turned-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------------+\n",
      "|            features|total_amount|         prediction|\n",
      "+--------------------+------------+-------------------+\n",
      "|(11,[0,1,2,3,4,9]...|        62.8|  52.57105177372951|\n",
      "|(11,[0,1,2,3,4,9]...|       100.3| 117.76367886178866|\n",
      "|(11,[0,1,2,3,9],[...|         0.3|  8.851457709186821|\n",
      "|(11,[0,1,3],[1.0,...|         0.0|-10.145543893129787|\n",
      "|(11,[0,1,3],[1.0,...|         0.0|-10.145543893129787|\n",
      "+--------------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = dt_model.transform(test_df)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "announced-belarus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4.95571\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "affecting-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "#We scale features to be between 0 and 1 to prevent the exploding gradient problem\n",
    "\n",
    "featureScaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\").fit(vtripdata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "recorded-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+--------------------+\n",
      "|        prediction|total_amount|            features|\n",
      "+------------------+------------+--------------------+\n",
      "|1.2424141894171044|        62.8|(11,[0,1,2,3,4,9]...|\n",
      "| 1.469689181808229|       100.3|(11,[0,1,2,3,4,9]...|\n",
      "|1.4285877545808996|         0.3|(11,[0,1,2,3,9],[...|\n",
      "|0.7443631771994863|         0.0|(11,[0,1,3],[1.0,...|\n",
      "| 0.744363369941704|         0.0|(11,[0,1,3],[1.0,...|\n",
      "+------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 20.7713\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import FMRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Train a FM model.\n",
    "fm = FMRegressor(featuresCol=\"scaledFeatures\", labelCol=\"total_amount\", stepSize=0.001)\n",
    "\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=[featureScaler, fm])\n",
    "\n",
    "# Train model.\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"total_amount\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
