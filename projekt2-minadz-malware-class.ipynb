{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('minadz').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regional-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('Malware_Classification.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interesting-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- md5: string (nullable = true)\n",
      " |-- Machine: string (nullable = true)\n",
      " |-- SizeOfOptionalHeader: integer (nullable = true)\n",
      " |-- Characteristics: integer (nullable = true)\n",
      " |-- MajorLinkerVersion: integer (nullable = true)\n",
      " |-- MinorLinkerVersion: integer (nullable = true)\n",
      " |-- SizeOfCode: long (nullable = true)\n",
      " |-- SizeOfInitializedData: long (nullable = true)\n",
      " |-- SizeOfUninitializedData: long (nullable = true)\n",
      " |-- AddressOfEntryPoint: long (nullable = true)\n",
      " |-- BaseOfCode: long (nullable = true)\n",
      " |-- BaseOfData: integer (nullable = true)\n",
      " |-- ImageBase: double (nullable = true)\n",
      " |-- SectionAlignment: integer (nullable = true)\n",
      " |-- FileAlignment: integer (nullable = true)\n",
      " |-- MajorOperatingSystemVersion: integer (nullable = true)\n",
      " |-- MinorOperatingSystemVersion: integer (nullable = true)\n",
      " |-- MajorImageVersion: integer (nullable = true)\n",
      " |-- MinorImageVersion: integer (nullable = true)\n",
      " |-- MajorSubsystemVersion: integer (nullable = true)\n",
      " |-- MinorSubsystemVersion: integer (nullable = true)\n",
      " |-- SizeOfImage: integer (nullable = true)\n",
      " |-- SizeOfHeaders: integer (nullable = true)\n",
      " |-- CheckSum: long (nullable = true)\n",
      " |-- Subsystem: integer (nullable = true)\n",
      " |-- DllCharacteristics: integer (nullable = true)\n",
      " |-- SizeOfStackReserve: double (nullable = true)\n",
      " |-- SizeOfStackCommit: double (nullable = true)\n",
      " |-- SizeOfHeapReserve: long (nullable = true)\n",
      " |-- SizeOfHeapCommit: integer (nullable = true)\n",
      " |-- LoaderFlags: long (nullable = true)\n",
      " |-- NumberOfRvaAndSizes: long (nullable = true)\n",
      " |-- SectionsNb: integer (nullable = true)\n",
      " |-- SectionsMeanEntropy: double (nullable = true)\n",
      " |-- SectionsMinEntropy: double (nullable = true)\n",
      " |-- SectionsMaxEntropy: double (nullable = true)\n",
      " |-- SectionsMeanRawsize: double (nullable = true)\n",
      " |-- SectionsMinRawsize: integer (nullable = true)\n",
      " |-- SectionMaxRawsize: long (nullable = true)\n",
      " |-- SectionsMeanVirtualsize: double (nullable = true)\n",
      " |-- SectionsMinVirtualsize: double (nullable = true)\n",
      " |-- SectionMaxVirtualsize: long (nullable = true)\n",
      " |-- ImportsNbDLL: integer (nullable = true)\n",
      " |-- ImportsNb: integer (nullable = true)\n",
      " |-- ImportsNbOrdinal: integer (nullable = true)\n",
      " |-- ExportNb: integer (nullable = true)\n",
      " |-- ResourcesNb: integer (nullable = true)\n",
      " |-- ResourcesMeanEntropy: double (nullable = true)\n",
      " |-- ResourcesMinEntropy: double (nullable = true)\n",
      " |-- ResourcesMaxEntropy: double (nullable = true)\n",
      " |-- ResourcesMeanSize: double (nullable = true)\n",
      " |-- ResourcesMinSize: double (nullable = true)\n",
      " |-- ResourcesMaxSize: long (nullable = true)\n",
      " |-- LoadConfigurationSize: long (nullable = true)\n",
      " |-- VersionInformationSize: integer (nullable = true)\n",
      " |-- legitimate: integer (nullable = true)\n",
      " |-- _c57: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.summary of DataFrame[ID: int, md5: string, Machine: string, SizeOfOptionalHeader: int, Characteristics: int, MajorLinkerVersion: int, MinorLinkerVersion: int, SizeOfCode: bigint, SizeOfInitializedData: bigint, SizeOfUninitializedData: bigint, AddressOfEntryPoint: bigint, BaseOfCode: bigint, BaseOfData: int, ImageBase: double, SectionAlignment: int, FileAlignment: int, MajorOperatingSystemVersion: int, MinorOperatingSystemVersion: int, MajorImageVersion: int, MinorImageVersion: int, MajorSubsystemVersion: int, MinorSubsystemVersion: int, SizeOfImage: int, SizeOfHeaders: int, CheckSum: bigint, Subsystem: int, DllCharacteristics: int, SizeOfStackReserve: double, SizeOfStackCommit: double, SizeOfHeapReserve: bigint, SizeOfHeapCommit: int, LoaderFlags: bigint, NumberOfRvaAndSizes: bigint, SectionsNb: int, SectionsMeanEntropy: double, SectionsMinEntropy: double, SectionsMaxEntropy: double, SectionsMeanRawsize: double, SectionsMinRawsize: int, SectionMaxRawsize: bigint, SectionsMeanVirtualsize: double, SectionsMinVirtualsize: double, SectionMaxVirtualsize: bigint, ImportsNbDLL: int, ImportsNb: int, ImportsNbOrdinal: int, ExportNb: int, ResourcesNb: int, ResourcesMeanEntropy: double, ResourcesMinEntropy: double, ResourcesMaxEntropy: double, ResourcesMeanSize: double, ResourcesMinSize: double, ResourcesMaxSize: bigint, LoadConfigurationSize: bigint, VersionInformationSize: int, legitimate: int, _c57: int]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hazardous-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"ID\", \"md5\", \"Machine\", \"_c57\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noble-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.summary of DataFrame[SizeOfOptionalHeader: int, Characteristics: int, MajorLinkerVersion: int, MinorLinkerVersion: int, SizeOfCode: bigint, SizeOfInitializedData: bigint, SizeOfUninitializedData: bigint, AddressOfEntryPoint: bigint, BaseOfCode: bigint, BaseOfData: int, ImageBase: double, SectionAlignment: int, FileAlignment: int, MajorOperatingSystemVersion: int, MinorOperatingSystemVersion: int, MajorImageVersion: int, MinorImageVersion: int, MajorSubsystemVersion: int, MinorSubsystemVersion: int, SizeOfImage: int, SizeOfHeaders: int, CheckSum: bigint, Subsystem: int, DllCharacteristics: int, SizeOfStackReserve: double, SizeOfStackCommit: double, SizeOfHeapReserve: bigint, SizeOfHeapCommit: int, LoaderFlags: bigint, NumberOfRvaAndSizes: bigint, SectionsNb: int, SectionsMeanEntropy: double, SectionsMinEntropy: double, SectionsMaxEntropy: double, SectionsMeanRawsize: double, SectionsMinRawsize: int, SectionMaxRawsize: bigint, SectionsMeanVirtualsize: double, SectionsMinVirtualsize: double, SectionMaxVirtualsize: bigint, ImportsNbDLL: int, ImportsNb: int, ImportsNbOrdinal: int, ExportNb: int, ResourcesNb: int, ResourcesMeanEntropy: double, ResourcesMinEntropy: double, ResourcesMaxEntropy: double, ResourcesMeanSize: double, ResourcesMinSize: double, ResourcesMaxSize: bigint, LoadConfigurationSize: bigint, VersionInformationSize: int, legitimate: int]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-impact",
   "metadata": {},
   "source": [
    "### Find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dietary-fruit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SizeOfOptionalHeader</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>MajorLinkerVersion</th>\n",
       "      <th>MinorLinkerVersion</th>\n",
       "      <th>SizeOfCode</th>\n",
       "      <th>SizeOfInitializedData</th>\n",
       "      <th>SizeOfUninitializedData</th>\n",
       "      <th>AddressOfEntryPoint</th>\n",
       "      <th>BaseOfCode</th>\n",
       "      <th>BaseOfData</th>\n",
       "      <th>...</th>\n",
       "      <th>ResourcesNb</th>\n",
       "      <th>ResourcesMeanEntropy</th>\n",
       "      <th>ResourcesMinEntropy</th>\n",
       "      <th>ResourcesMaxEntropy</th>\n",
       "      <th>ResourcesMeanSize</th>\n",
       "      <th>ResourcesMinSize</th>\n",
       "      <th>ResourcesMaxSize</th>\n",
       "      <th>LoadConfigurationSize</th>\n",
       "      <th>VersionInformationSize</th>\n",
       "      <th>legitimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SizeOfOptionalHeader  Characteristics  MajorLinkerVersion  \\\n",
       "0                     0                0                   1   \n",
       "\n",
       "   MinorLinkerVersion  SizeOfCode  SizeOfInitializedData  \\\n",
       "0                   0           0                      0   \n",
       "\n",
       "   SizeOfUninitializedData  AddressOfEntryPoint  BaseOfCode  BaseOfData  ...  \\\n",
       "0                        0                    0           0           0  ...   \n",
       "\n",
       "   ResourcesNb  ResourcesMeanEntropy  ResourcesMinEntropy  \\\n",
       "0            0                     0                    0   \n",
       "\n",
       "   ResourcesMaxEntropy  ResourcesMeanSize  ResourcesMinSize  ResourcesMaxSize  \\\n",
       "0                    0                  0                 0                 0   \n",
       "\n",
       "   LoadConfigurationSize  VersionInformationSize  legitimate  \n",
       "0                      0                       0           0  \n",
       "\n",
       "[1 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "nacounts = data.select([count(when(isnull(c), c)).alias(c) for c in data.columns]).toPandas()\n",
    "nacounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hispanic-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(strategy='mean', inputCols=['MajorLinkerVersion'], outputCols=['MajorLinkerVersionImputed'])\n",
    "imputer_model = imputer.fit(data)\n",
    "data = imputer_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "irish-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"SizeOfOptionalHeader\",  \"Characteristics\", \"MajorLinkerVersionImputed\",  \"MinorLinkerVersion\", \"SizeOfCode\", \"SizeOfInitializedData\", \"SizeOfUninitializedData\", \"AddressOfEntryPoint\", \"BaseOfCode\", \"BaseOfData\", \"ImageBase\", \"SectionAlignment\", \"FileAlignment\", \"MajorOperatingSystemVersion\", \"MinorOperatingSystemVersion\", \"MajorImageVersion\", \"MinorImageVersion\", \"MajorSubsystemVersion\", \"MinorSubsystemVersion\", \"SizeOfImage\", \"SizeOfHeaders\", \"CheckSum\", \"Subsystem\", \"DllCharacteristics\", \"SizeOfStackReserve\", \"SizeOfStackCommit\", \"SizeOfHeapReserve\", \"SizeOfHeapCommit\", \"LoaderFlags\", \"NumberOfRvaAndSizes\", \"SectionsNb\", \"SectionsMeanEntropy\", \"SectionsMinEntropy\", \"SectionsMaxEntropy\", \"SectionsMeanRawsize\", \"SectionsMinRawsize\", \"SectionMaxRawsize\", \"SectionsMeanVirtualsize\", \"SectionsMinVirtualsize\", \"SectionMaxVirtualsize\", \"ImportsNbDLL\", \"ImportsNb\", \"ImportsNbOrdinal\", \"ExportNb\", \"ResourcesNb\", \"ResourcesMeanEntropy\", \"ResourcesMinEntropy\", \"ResourcesMaxEntropy\", \"ResourcesMeanSize\", \"ResourcesMinSize\", \"ResourcesMaxSize\", \"LoadConfigurationSize\", \"VersionInformationSize\"], outputCol='features')\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clear-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.select(['features', \"SizeOfOptionalHeader\",  \"Characteristics\", \"MajorLinkerVersionImputed\",  \"MinorLinkerVersion\", \"SizeOfCode\", \"SizeOfInitializedData\", \"SizeOfUninitializedData\", \"AddressOfEntryPoint\", \"BaseOfCode\", \"BaseOfData\", \"ImageBase\", \"SectionAlignment\", \"FileAlignment\", \"MajorOperatingSystemVersion\", \"MinorOperatingSystemVersion\", \"MajorImageVersion\", \"MinorImageVersion\", \"MajorSubsystemVersion\", \"MinorSubsystemVersion\", \"SizeOfImage\", \"SizeOfHeaders\", \"CheckSum\", \"Subsystem\", \"DllCharacteristics\", \"SizeOfStackReserve\", \"SizeOfStackCommit\", \"SizeOfHeapReserve\", \"SizeOfHeapCommit\", \"LoaderFlags\", \"NumberOfRvaAndSizes\", \"SectionsNb\", \"SectionsMeanEntropy\", \"SectionsMinEntropy\", \"SectionsMaxEntropy\", \"SectionsMeanRawsize\", \"SectionsMinRawsize\", \"SectionMaxRawsize\", \"SectionsMeanVirtualsize\", \"SectionsMinVirtualsize\", \"SectionMaxVirtualsize\", \"ImportsNbDLL\", \"ImportsNb\", \"ImportsNbOrdinal\", \"ExportNb\", \"ResourcesNb\", \"ResourcesMeanEntropy\", \"ResourcesMinEntropy\", \"ResourcesMaxEntropy\", \"ResourcesMeanSize\", \"ResourcesMinSize\", \"ResourcesMaxSize\", \"LoadConfigurationSize\", \"VersionInformationSize\",'legitimate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electrical-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select(['features', 'legitimate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alternative-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cutting-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "algo = RandomForestClassifier(featuresCol='features', labelCol='legitimate')\n",
    "model = algo.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "guilty-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "figured-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|legitimate|prediction|         probability|\n",
      "+----------+----------+--------------------+\n",
      "|         1|       0.0|[0.95158184768211...|\n",
      "|         1|       0.0|[0.68079237973829...|\n",
      "|         1|       0.0|[0.91056105431035...|\n",
      "|         1|       0.0|[0.67233476361631...|\n",
      "|         1|       0.0|[0.96804068299810...|\n",
      "|         1|       0.0|[0.93465787042471...|\n",
      "|         1|       0.0|[0.97135549388957...|\n",
      "|         1|       0.0|[0.93873568903949...|\n",
      "|         1|       0.0|[0.95473616762003...|\n",
      "|         1|       0.0|[0.76844392905985...|\n",
      "|         1|       0.0|[0.88544421989693...|\n",
      "|         1|       0.0|[0.64977234542762...|\n",
      "|         1|       0.0|[0.67971891791698...|\n",
      "|         1|       0.0|[0.67823651043939...|\n",
      "|         1|       0.0|[0.72961451362673...|\n",
      "|         1|       0.0|[0.72961451362673...|\n",
      "|         1|       0.0|[0.67971891791698...|\n",
      "|         1|       0.0|[0.72813210614914...|\n",
      "|         1|       0.0|[0.72813210614914...|\n",
      "|         1|       0.0|[0.67971891791698...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(['legitimate','prediction', 'probability']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handmade-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Create both evaluators\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"legitimate\", predictionCol=\"prediction\")\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"legitimate\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "\n",
    "# Make predicitons\n",
    "predictionAndTarget = model.transform(test_df).select(\"legitimate\", \"prediction\")\n",
    "\n",
    "# Get metrics\n",
    "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "auc = evaluator.evaluate(predictionAndTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accredited-porcelain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.96\n",
      "f1 score 0.96\n",
      "weighted precision 0.96\n",
      "weighted recall score 0.96\n",
      "area under roc score 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score %.2f\" % acc)\n",
    "print(\"f1 score %.2f\" % f1)\n",
    "print(\"weighted precision %.2f\" % weightedPrecision)\n",
    "print(\"weighted recall score %.2f\" % weightedRecall)\n",
    "print(\"area under roc score %.2f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "excited-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "# Make predicitons\n",
    "predictionAndTarget = model.transform(test_df).select(\"legitimate\", \"prediction\")\n",
    "\n",
    "predictionAndTargetNumpy = np.array((predictionAndTarget.collect()))\n",
    "\n",
    "acc = accuracy_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "f1 = f1_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "precision = precision_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "recall = recall_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "auc = roc_auc_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sweet-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.96\n",
      "f1 score 0.94\n",
      "weighted precision 0.94\n",
      "weighted recall score 0.95\n",
      "area under roc score 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score %.2f\" % acc)\n",
    "print(\"f1 score %.2f\" % f1)\n",
    "print(\"weighted precision %.2f\" % precision)\n",
    "print(\"weighted recall score %.2f\" % recall)\n",
    "print(\"area under roc score %.2f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "virgin-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, featuresCol='features', labelCol='legitimate')\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incorrect-custody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.65\n",
      "f1 score 0.51\n",
      "weighted precision 0.42\n",
      "weighted recall score 0.65\n",
      "area under roc score 0.50\n"
     ]
    }
   ],
   "source": [
    "# Create both evaluators\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"legitimate\", predictionCol=\"prediction\")\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"legitimate\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "\n",
    "# Make predicitons\n",
    "predictionAndTarget = lrModel.transform(test_df).select(\"legitimate\", \"prediction\")\n",
    "\n",
    "# Get metrics\n",
    "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "auc = evaluator.evaluate(predictionAndTarget)\n",
    "\n",
    "print(\"accuracy score %.2f\" % acc)\n",
    "print(\"f1 score %.2f\" % f1)\n",
    "print(\"weighted precision %.2f\" % weightedPrecision)\n",
    "print(\"weighted recall score %.2f\" % weightedRecall)\n",
    "print(\"area under roc score %.2f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indonesian-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"legitimate\", featuresCol=\"features\")\n",
    "dtModel = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "soviet-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.97\n",
      "f1 score 0.97\n",
      "weighted precision 0.97\n",
      "weighted recall score 0.97\n",
      "area under roc score 0.96\n"
     ]
    }
   ],
   "source": [
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"legitimate\", predictionCol=\"prediction\")\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"legitimate\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "\n",
    "predictionAndTarget = dtModel.transform(test_df).select(\"legitimate\", \"prediction\")\n",
    "\n",
    "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "auc = evaluator.evaluate(predictionAndTarget)\n",
    "\n",
    "print(\"accuracy score %.2f\" % acc)\n",
    "print(\"f1 score %.2f\" % f1)\n",
    "print(\"weighted precision %.2f\" % weightedPrecision)\n",
    "print(\"weighted recall score %.2f\" % weightedRecall)\n",
    "print(\"area under roc score %.2f\" % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thorough-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", labelCol=\"legitimate\", featuresCol=\"features\")\n",
    "\n",
    "nbModel = nb.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ready-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.70\n",
      "f1 score 0.61\n",
      "weighted precision 0.79\n",
      "weighted recall score 0.70\n",
      "area under roc score 0.57\n"
     ]
    }
   ],
   "source": [
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"legitimate\", predictionCol=\"prediction\")\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"legitimate\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "\n",
    "predictionAndTarget = nbModel.transform(test_df).select(\"legitimate\", \"prediction\")\n",
    "\n",
    "acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "auc = evaluator.evaluate(predictionAndTarget)\n",
    "\n",
    "print(\"accuracy score %.2f\" % acc)\n",
    "print(\"f1 score %.2f\" % f1)\n",
    "print(\"weighted precision %.2f\" % weightedPrecision)\n",
    "print(\"weighted recall score %.2f\" % weightedRecall)\n",
    "print(\"area under roc score %.2f\" % auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
